# AWS S3 Storage

store objects (files) in buckets (directories)

## Buckets
- bucket names are globally unique 
- buckets defined at region level
- naming convention
    - no uppercase
    - no underscore
    - 3-63 characters long
    - not an IP
    - start with lowercase letter or number

## Objects

- key is the FULL path to the file
- keys basically very long names that contain slashes "/"
    - a way to partition files
- max size is 5TB for one object
- if uploading more than 5 GB must use "multi-part upload"
- if uploading more than 100 MB "multi-part upload" recommended
- versioning optional
- metadata and tags

- Read after write consistency for PUTS of new objects
- [Strong read after write consistency of existing objects since 2020-12](https://aws.amazon.com/blogs/aws/amazon-s3-update-strong-read-after-write-consistency/) 

No longer needs to overhead use EMRFS for EMR with DynamoDB to checkpoint files to ensure consistency.

[Outdated]
Eventual consistency for GETs, PUTS, LISTs for existing objects

## Storage Tiers

### Standard
- high durability (eleven 9's) across multiple AZ (>= 3)
- high availability 99.99%
- sustain 2 concurrent facility failures
- Ex. us-east-2 $0.023 storage cost per GB per month 

### Standard-Infrequent Access (IA)
- 99.9% availability
- lower cost compared to Standard
- stored in multiple AZ
- minimum capacity charge per object 128 kb
- minimum storage duration 30 days
- Ex. us-east-2 
    - $0.0125 storage cost per GB per month
    - GET $0.001 per 1000 requests

### One Zone-Infrequent Access (IA)
- data is stored in single AZ
- 99.9% availability
- 20% lower cost than IA
- storing data you can recreate, secondary backup copies on on-premise data

### Intelligent Tiering
- small monthly monitoring and auto-tiering fee
    - Ex. us-east-2 is $0.0025 per 1000 objects per month
    - GET $0.0004 per 1000 requests
- automatically moves objects between 4 access tiers based on changing access patterns

- [2020-11 Intelligent Tier adds Archive and Deep Archive Tiers](https://aws.amazon.com/blogs/aws/s3-intelligent-tiering-adds-archive-access-tiers/)


### Glacier
- low cost object storage meant for archiving/backup
- for data to be retained for 10s of years
- alternative to on-premise storage
- each item is called an "Archive" (up to 40 TB each)
- stored in "Vaults"

Retrieval options:
- GET $0.0004 +
- Expedited (1 to 5 minutes) - $10.00 per 1000
- Standard (3 to 5 hours) - $0.05 per 1000
- Bulk (5 to 12 hours) - $0.025 per 1000
- charged per GB

- minimum capacity charge per object 40 kb
- minimum storage duration 90 days

[For further details on restoring archived objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/restoring-objects.html)

#### Vault Policy and Vault Lock

- Vault is collection of archives
- each has ONE access and lock policy
- lock policy for regulatory and compliance requirements
    - is immutable and can never be changed
    - Ex. forbid deleting archive if less than 1 year old
    - Ex. WORM policy (write once read many)


### Glacier Deep Archive
- GET $0.0004 +
- standard (12 hours) - $0.10 per 1000
- bulk (48 hours) = $0.025 per 1000

- minimum capacity charge per object 40 kb
- minimum storage duration of 180 days
    - $0.00099 storage cost per GB per month

### Reduced Redundancy (deprecated)

## Lifecycle Rules

<img src="./assets/aws_s3_storage_class_transitions.png" 
alt="AWS S3 Class Transitions" width="400" />

- Rules can be created for specific prefix
- Rules can be created for specific tags

### Transition actions
- Ex. moving objects to Standard IA 60 days after creation
- Move to Glacier for archiving after 6 months

### Expiration actions
- Ex. delete objects after 365 days
- Ex. delete old versions of files if versioning enabled
- Ex. delete incomplete multi-part uploads

## Versioning

- any file that is not versioned prior to enabling versioning will have version "null"
- version ID is a long hash string
- a delete marker is added at time of deletion to versioned file
- deleting the market will roll back to previous version available

## Cross Region Replication

- will only be applied to new objects after replication is enabled
- can specify entire bucket or specific prefix
- likely choose to enable change ownership to destination bucket owner
- must enable versioning (source and destination)
- must give proper IAM permissions to S3
- copying is asynchronous
- use cases: compliance, lower latency, cross account replication to closer region to actual usage

## ETags

- allows verification of file contents
- for simple uploads less than 5GB it's the MD5 hash
- multi part upload ETags more complicated

## Performance

- latency 100-200 ms
- 3.5K PUT/COPY/POST/DELETE and 5.5K GET/HEAD requests per second per prefix in a bucket
- no limits to prefix in bucket

S3 Transfer Acceleration (upload only)
- transfer file to AWS Edge location to forward data to S3 bucket in target region (increase time spent in private AWS network)

- Parallelize GETs by requesting specific byte ranges for better resilience in case of failures (speed up downloads or partial file data like headers)

## Encryption 

- if you use SSE-KMS impacted by KMS limits
- GenerateDataKey called on upload
- Decrypt KMS API called on download
- depending on region 5.5K, 10K or 30K req/s cannot request     quota increase for KMS

4 methods
- SSE-S3 - object encrypted server side managed by S3 with AES-256
    - request set header "x-amz-server-side-encryption": "AES256"
- SSE-KMS - use KMS for managing encryption keys
    - user control + audit trail
    - encrypted server side with KMS Customer Master Key (CMK)
    - - request set header "x-amz-server-side-encryption": "aws:kms"
- SSE-C - manage your own encryption keys
    - https must be used
    - encryption key must be provided in headers for every request made
- Client Side Encryption
    - AWS S3 Encryption Client
    - Client must encrypt and decrypt data before sending data and after getting data from S3

Encryption in flight - SSL / TLS

## Security

### CORS (Cross Origin Resource Sharing)

- limit specific websites able to request S3 files

### Access Logs

- for audit purposes so any request made to S3 from any account, authorized or denied with be logged in another S3 bucket
- access logs can be analyzed later with AWS Athena

### Bucket Policies

- JSON based 
    - Resources: buckets and objects
    - Actions: Set of APIs
    - Principal: account or user to apply
    - Effect: Allow/Deny

- Use Cases
    - Grant access to another account
    - Grant public access
    - Force objects to be encrypted at upload

### Other

- Signed URLs valid for limited time
- MFA multi factor authentication for example to delete objects

### S3 Select and Glacier Select

- filter by rows and columns in simple SQL to reduce data transferred from S3 to Hadoop for example
- server-side filtering

